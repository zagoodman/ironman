{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-and-explore-data\" data-toc-modified-id=\"Import-and-explore-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import and explore data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-race-specific-variables\" data-toc-modified-id=\"Load-race-specific-variables-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load race-specific variables</a></span></li><li><span><a href=\"#Set-up-RD\" data-toc-modified-id=\"Set-up-RD-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Set up RD</a></span></li></ul></li><li><span><a href=\"#Effect-of-wetsuits\" data-toc-modified-id=\"Effect-of-wetsuits-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Effect of wetsuits</a></span></li><li><span><a href=\"#Export-html\" data-toc-modified-id=\"Export-html-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Export html</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/dfm_20201022.csv')\n",
    "print(df.isnull().sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer vars\n",
    "\n",
    "for v in ['seriesid', 'raceid', 'raceyear', 'bib_n', 'autokonaqual']:\n",
    "    df[v] = np.array(df[v], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine finishers by year\n",
    "display(pd.crosstab(df.raceyear, df.finish, margins='all'))\n",
    "\n",
    "# examine percent finishers by year\n",
    "display(pd.crosstab(df.raceyear, df.finish, normalize='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of race-years\n",
    "print(len(df.racename.unique()))\n",
    "print(len(df[['racename', 'racedate']].drop_duplicates()))\n",
    "\n",
    "# number of races by year\n",
    "display(df[['racename', 'raceyear']].drop_duplicates().raceyear.value_counts().sort_index())\n",
    "\n",
    "# number of years by race venue\n",
    "df['venuename'] = df.racename.apply(lambda x: x[8:-5])\n",
    "display(df[['venuename', 'raceyear']].drop_duplicates().venuename.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean swim times: set to zero if swim cancelled\n",
    "\n",
    "# weird circumstances:\n",
    "# Hamburg 2018: swim replaced with run\n",
    "\n",
    "noswim_races =  ['Ironman Chattanooga 2018',\n",
    "                 'Ironman Florida 2014',\n",
    "                 'Ironman Hamburg 2018',\n",
    "                 'Ironman Ireland 2019',\n",
    "                 'Ironman Louisville 2019',\n",
    "                 'Ironman Maryland 2016',\n",
    "                 'Ironman Western Australia 2017',\n",
    "                 'Ironman New Zealand 2006']\n",
    "\n",
    "df['noswim'] = np.array(df.racename.isin(noswim_races), dtype='int')\n",
    "print(df.noswim.value_counts() / len(df))\n",
    "\n",
    "\n",
    "# if swim cancelled, set swim time to 0 instead of missing\n",
    "df.loc[df.noswim == 1, 'swimtime'] = 0\n",
    "df.loc[df.noswim == 1, 'trans1time'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen variable to designate races that were shortened or otherwise adjusted\n",
    "\n",
    "short_races = noswim_races + [\\\n",
    "                'Ironman Argentina 2018', # swim shortened\n",
    "                \"Ironman Coeur d'Alene 2007\", # swim optional, though not for WC qualification\n",
    "                'Ironman Cozumel 2013', # swim shortened\n",
    "                'Ironman France 2019', # bike and run shortened b/c heat\n",
    "                'Ironman Lake Placid 2014', # swim shortened for amateurs only\n",
    "                'Ironman Louisville 2018', # swim shortened\n",
    "                'Ironman Lake Placid 2014', # swim shortened for 1/3 of amateurs\n",
    "                'Ironman Maryland 2015', # swim shortened\n",
    "                'Ironman Maryland 2016', # bike course shortened, swim cancelled\n",
    "                'Ironman Melbourne 2013', # swim shortened\n",
    "                'Ironman New Zealand 2006', # bike and run halved, swim cancelled\n",
    "                'Ironman New Zealand 2012', # all three events halved\n",
    "                'Ironman North Carolina 2016', # bike shortened\n",
    "                'Ironman South Africa 2019', # swim shortened\n",
    "                'Ironman Taiwan 2018', # swim shortened\n",
    "                'Ironman Texas 2016', # bike shortened\n",
    "                'Ironman Western Australia 2017'] # bike shortened for slower athletes only\n",
    "\n",
    "# other weird stuff:\n",
    "# Cozumel 2017/9, Louisville 2014, New York 2012 had irregularly fast currents during swim\n",
    "# Texas 2017/8 bike short by 2 miles\n",
    "# Florida 2018: Hurricane Michael caused change in data and venue, field size less than half of registrants\n",
    "# St George 2012: Strong winds made for a particularly challenging swim, lots of DNFs\n",
    "# Frankfurt 2019, Chattanooga 2016/9, etc: Super hot, strong influence on DNFs, particularly during run\n",
    "                                \n",
    "df['short'] = np.array(df.racename.isin(short_races), dtype='int')\n",
    "print(df.short.value_counts() / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check swim finishers per race\n",
    "dfsub = df.loc[df.short == 0, ['racename', 'venuename', 'swimtime']]\n",
    "display(pd.crosstab(dfsub.venuename, dfsub.swimtime > 0, normalize='index').sort_values(1))\n",
    "\n",
    "# check a few of the offenders:\n",
    "venuenames = ['St George', \n",
    "               'New York', \n",
    "               'Argentina', \n",
    "               'Florida', \n",
    "               'Vineman']\n",
    "dfsub = dfsub.loc[dfsub.venuename.isin(venuenames), :]\n",
    "display(pd.crosstab(dfsub.racename, dfsub.swimtime > 0, normalize='index').sort_values(1))\n",
    "\n",
    "# check the worst races for DNFs\n",
    "dfsub = df.loc[df.finish.isin(['DNF', 'FIN']), ['racename', 'finish']]\n",
    "display(pd.crosstab(dfsub.racename, dfsub.finish, normalize='index').sort_values('FIN').head(20))\n",
    "\n",
    "# Race temperature and winds likely affect performance enough that controlling for weather may\n",
    "#  improve statistical power...\n",
    "# When we pull water temperature data may be useful to get other weather data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix kona year and dates for a few races\n",
    "df.loc[df.racename == \"Ironman St George 2011\", 'konayear'] = 2011\n",
    "df.loc[df.racename == \"Ironman St George 2010\", 'konayear'] = 2010\n",
    "df.loc[df.racename == \"Ironman Regensburg 2011\", 'konayear'] = 2011\n",
    "df.loc[df.racename == \"Ironman Malaysia 2006\", 'konayear'] = 2006\n",
    "df.loc[df.racename == \"Ironman Malaysia 2007\", 'konayear'] = 2007\n",
    "df.loc[df.racename == \"Ironman China 2009\", 'konayear'] = 2009\n",
    "df.loc[df.racename == \"Ironman China 2010\", 'konayear'] = 2010\n",
    "df.loc[df.racename == \"Ironman China 2010\", 'racedate'] = \"14 Mar 2010\"\n",
    "df.loc[df.racename == \"Ironman China 2009\", 'racedate'] = \"19 Apr 2009\"\n",
    "df.loc[df.racename == \"Ironman Malaysia 2006\", 'racedate'] = \"26 Feb 2006\"\n",
    "df.loc[df.racename == \"Ironman Malaysia 2007\", 'racedate'] = \"24 Feb 2007\"\n",
    "\n",
    "df['konayear'] = np.array(df.konayear, dtype='int')\n",
    "print(df.konayear.isnull().sum())\n",
    "print(df.konayear.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load race-specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df with slots per ag per race\n",
    "dfs = pd.read_csv('../data/dfslot_full_wide.csv')\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge race-specific vars, like # finishers, % finishers\n",
    "\n",
    "dfrace = df.copy()\n",
    "\n",
    "# get dnf rates by sport - only count one sport for DNF\n",
    "dfrace['swimdnf'] = np.array((dfrace.swimtime.isnull()) & (dfrace.finish == \"DNF\"), dtype='int')\n",
    "dfrace['bikednf'] = np.array((dfrace.biketime.isnull()) & (dfrace.finish == \"DNF\") & \\\n",
    "                             (dfrace.swimdnf == 0), dtype='int')\n",
    "dfrace['rundnf'] = np.array((dfrace.runtime.isnull()) & (dfrace.finish == \"DNF\") & \\\n",
    "                            (dfrace.bikednf + dfrace.swimdnf == 0), dtype='int')\n",
    "dfrace['dnf'] = np.array((dfrace.finish == \"DNF\"), dtype='int')\n",
    "dfrace['dq'] = np.array((dfrace.finish == \"DQ\"), dtype='int')\n",
    "\n",
    "# get participant and finisher counts\n",
    "dfrace['participants'] = np.array(dfrace.finish.notnull(), dtype='int')\n",
    "dfrace['finishers'] = np.array(dfrace.finish == \"FIN\", dtype='int')\n",
    "dfrace.participants = dfrace.groupby('racename')['participants'].transform('sum')\n",
    "dfrace.finishers = dfrace.groupby('racename')['finishers'].transform('sum')\n",
    "\n",
    "# gender split\n",
    "dfrace['female'] = np.array(dfrace.gender == 'Female', dtype='int')\n",
    "\n",
    "# aggregate to race-level\n",
    "dfrace = dfrace.groupby(['racename', 'venuename', 'seriesid', 'raceyear', \\\n",
    "                         'racedate', 'konayear'],  as_index=False, observed=False)\\\n",
    "                    [['noswim', 'short', 'swimdnf', 'bikednf', \\\n",
    "                      'rundnf', 'dnf', 'dq', 'participants', \\\n",
    "                      'finishers', 'female']].aggregate(np.mean)\n",
    "\n",
    "# integer vars\n",
    "for i in ['noswim', 'short', 'participants', 'finishers']:\n",
    "    dfrace[i] = np.array(dfrace[i], dtype='int')\n",
    "\n",
    "dfrace.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix this inconsistency\n",
    "df.loc[df.seriesid == 54].racename.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up RD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cutoff times to dfs\n",
    "divlist = ['F18-24', 'F25-29', 'F30-34', 'F35-39', 'F40-44', 'F45-49', 'F50-54', \n",
    "           'F55-59', 'F60-64', 'F65-69', 'F70-74', 'F75-79', 'F80+', 'FPC', 'FPRO', \n",
    "           'M18-24', 'M25-29', 'M30-34', 'M35-39', 'M40-44', 'M45-49', 'M50-54', \n",
    "           'M55-59', 'M60-64', 'M65-69', 'M70-74', 'M75-79', 'M80+', 'M80-84', 'MPC', 'MPRO']\n",
    "racelist = df.racename.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of wetsuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export html\n",
    "\n",
    "Before committing:\n",
    "1. Save nb as html\n",
    "2. Clear nb of output (cell -> All output -> clear)\n",
    "3. Save nb\n",
    "4. Commit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --output-dir='../jupyter_html/' --to html analyze_imdata.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

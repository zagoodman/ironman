{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-and-explore-data\" data-toc-modified-id=\"Import-and-explore-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import and explore data</a></span></li><li><span><a href=\"#Effect-of-wetsuits\" data-toc-modified-id=\"Effect-of-wetsuits-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Effect of wetsuits</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-race-specific-variables\" data-toc-modified-id=\"Load-race-specific-variables-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load race-specific variables</a></span></li><li><span><a href=\"#Set-up-RD\" data-toc-modified-id=\"Set-up-RD-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Set up RD</a></span></li></ul></li><li><span><a href=\"#Export-html\" data-toc-modified-id=\"Export-html-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Export html</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/dfm_20201022.csv')\n",
    "print(df.isnull().sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer vars\n",
    "\n",
    "for v in ['seriesid', 'raceid', 'raceyear', 'bib_n', 'autokonaqual']:\n",
    "    df[v] = np.array(df[v], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine finishers by year\n",
    "display(pd.crosstab(df.raceyear, df.finish, margins='all'))\n",
    "\n",
    "# examine percent finishers by year\n",
    "display(pd.crosstab(df.raceyear, df.finish, normalize='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of race-years\n",
    "print(len(df.racename.unique()))\n",
    "print(len(df[['racename', 'racedate']].drop_duplicates()))\n",
    "\n",
    "# number of races by year\n",
    "display(df[['racename', 'raceyear']].drop_duplicates().raceyear.value_counts().sort_index())\n",
    "\n",
    "# number of years by race venue\n",
    "df['venuename'] = df.racename.apply(lambda x: x[8:-5].lower())\n",
    "df.loc[df.venuename == 'e weymouth', 'venuename'] = 'weymouth'\n",
    "df.loc[df.venuename == 'man world championship', 'venuename'] = 'world championship'\n",
    "display(df[['venuename', 'raceyear']].drop_duplicates().venuename.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean swim times: set to zero if swim cancelled\n",
    "\n",
    "# weird circumstances:\n",
    "# Hamburg 2018: swim replaced with run\n",
    "\n",
    "noswim_races =  ['Ironman Chattanooga 2018',\n",
    "                 'Ironman Florida 2014',\n",
    "                 'Ironman Hamburg 2018',\n",
    "                 'Ironman Ireland 2019',\n",
    "                 'Ironman Louisville 2019',\n",
    "                 'Ironman Maryland 2016',\n",
    "                 'Ironman Western Australia 2017',\n",
    "                 'Ironman New Zealand 2006']\n",
    "\n",
    "df['noswim'] = np.array(df.racename.isin(noswim_races), dtype='int')\n",
    "print(df.noswim.value_counts() / len(df))\n",
    "\n",
    "\n",
    "# if swim cancelled, set swim time to 0 instead of missing\n",
    "df.loc[df.noswim == 1, 'swimtime'] = 0\n",
    "df.loc[df.noswim == 1, 'trans1time'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen variable to designate races that were shortened or otherwise adjusted\n",
    "\n",
    "short_races = noswim_races + [\\\n",
    "                'Ironman Argentina 2018', # swim shortened\n",
    "                \"Ironman Coeur d'Alene 2007\", # swim optional, though not for WC qualification\n",
    "                'Ironman Cozumel 2013', # swim shortened\n",
    "                'Ironman France 2019', # bike and run shortened b/c heat\n",
    "                'Ironman Lake Placid 2014', # swim shortened for amateurs only\n",
    "                'Ironman Louisville 2018', # swim shortened\n",
    "                'Ironman Lake Placid 2014', # swim shortened for 1/3 of amateurs\n",
    "                'Ironman Maryland 2015', # swim shortened\n",
    "                'Ironman Maryland 2016', # bike course shortened, swim cancelled\n",
    "                'Ironman Melbourne 2013', # swim shortened\n",
    "                'Ironman New Zealand 2006', # bike and run halved, swim cancelled\n",
    "                'Ironman New Zealand 2012', # all three events halved\n",
    "                'Ironman North Carolina 2016', # bike shortened\n",
    "                'Ironman South Africa 2019', # swim shortened\n",
    "                'Ironman Taiwan 2018', # swim shortened\n",
    "                'Ironman Texas 2016', # bike shortened\n",
    "                'Ironman Western Australia 2017'] # bike shortened for slower athletes only\n",
    "\n",
    "# other weird stuff:\n",
    "# Cozumel 2017/9, Louisville 2014, New York 2012 had irregularly fast currents during swim\n",
    "# Texas 2017/8 bike short by 2 miles\n",
    "# Florida 2018: Hurricane Michael caused change in data and venue, field size less than half of registrants\n",
    "# St George 2012: Strong winds made for a particularly challenging swim, lots of DNFs\n",
    "# Frankfurt 2019, Chattanooga 2016/9, etc: Super hot, strong influence on DNFs, particularly during run\n",
    "                                \n",
    "df['short'] = np.array(df.racename.isin(short_races), dtype='int')\n",
    "print(df.short.value_counts() / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check swim finishers per race\n",
    "dfsub = df.loc[df.short == 0, ['racename', 'venuename', 'swimtime']]\n",
    "display(pd.crosstab(dfsub.venuename, dfsub.swimtime > 0, normalize='index').sort_values(1))\n",
    "\n",
    "# check a few of the offenders:\n",
    "venuenames = ['St George', \n",
    "               'New York', \n",
    "               'Argentina', \n",
    "               'Florida', \n",
    "               'Vineman']\n",
    "dfsub = dfsub.loc[dfsub.venuename.isin(venuenames), :]\n",
    "display(pd.crosstab(dfsub.racename, dfsub.swimtime > 0, normalize='index').sort_values(1))\n",
    "\n",
    "# check the worst races for DNFs\n",
    "dfsub = df.loc[df.finish.isin(['DNF', 'FIN']), ['racename', 'finish']]\n",
    "display(pd.crosstab(dfsub.racename, dfsub.finish, normalize='index').sort_values('FIN').head(20))\n",
    "\n",
    "# Race temperature and winds likely affect performance enough that controlling for weather may\n",
    "#  improve statistical power...\n",
    "# When we pull water temperature data may be useful to get other weather data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix kona year and dates for a few races\n",
    "# df.loc[df.racename == \"Ironman St George 2011\", 'konayear'] = 2011\n",
    "# df.loc[df.racename == \"Ironman St George 2010\", 'konayear'] = 2010\n",
    "# df.loc[df.racename == \"Ironman Regensburg 2011\", 'konayear'] = 2011\n",
    "# df.loc[df.racename == \"Ironman Malaysia 2006\", 'konayear'] = 2006\n",
    "# df.loc[df.racename == \"Ironman Malaysia 2007\", 'konayear'] = 2007\n",
    "# df.loc[df.racename == \"Ironman China 2009\", 'konayear'] = 2009\n",
    "# df.loc[df.racename == \"Ironman China 2010\", 'konayear'] = 2010\n",
    "# df.loc[df.racename == \"Ironman China 2010\", 'racedate'] = \"14 Mar 2010\"\n",
    "# df.loc[df.racename == \"Ironman China 2009\", 'racedate'] = \"19 Apr 2009\"\n",
    "# df.loc[df.racename == \"Ironman Malaysia 2006\", 'racedate'] = \"26 Feb 2006\"\n",
    "# df.loc[df.racename == \"Ironman Malaysia 2007\", 'racedate'] = \"24 Feb 2007\"\n",
    "\n",
    "# df['konayear'] = np.array(df.konayear, dtype='int')\n",
    "# print(df.konayear.isnull().sum())\n",
    "# print(df.konayear.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of wetsuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import temp cutoff data\n",
    "\n",
    "files = ['amateur_cutoff.csv', 'pro_cutoff.csv']\n",
    "replace_dict = {'frankfurt (european champs)': 'frankfurt',\n",
    "                'canada penticton': 'canada',\n",
    "                'kona (world champs)': 'world championship',\n",
    "                'italy emilia romagna': 'italy',\n",
    "                'vitoria gasteiz': 'vitoria-gasteiz',\n",
    "                'duisburg': '70.3 duisburg',\n",
    "                'south africa (african champs)': 'south africa'}\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for i in range(2):\n",
    "    dfcut = pd.read_csv('../data/{}'.format(files[i]))\n",
    "    dfcut['venue'] = dfcut.venue.apply(lambda x: x[8:].rstrip())\n",
    "\n",
    "    dfcut['venue'] = dfcut.venue.apply(lambda x: replace_dict.get(x) if x in replace_dict.keys() else x)\n",
    "    dfcut = dfcut.loc[~dfcut.venue.str.contains('70.3'),\\\n",
    "                    [c for c in dfcut.columns if c != 'race_n']].\\\n",
    "                    reset_index(drop=True)\n",
    "    dataframes.append(dfcut)\n",
    "\n",
    "# combine dataframes\n",
    "dftemps = pd.concat([dataframes[0], dataframes[1]])\n",
    "dftemps = dftemps[['venue', 'avg_water_temp']].drop_duplicates().reset_index(drop=True)\n",
    "dftemps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge swim times and swim completion rates from df\n",
    "\n",
    "ag_divs = ['F18-24', 'F25-29', 'F30-34', 'F35-39', 'F40-44', 'F45-49', 'F50-54', \n",
    "           'F55-59', 'F60-64', 'F65-69', 'F70-74', 'F75-79', 'F80+',\n",
    "           'M18-24', 'M25-29', 'M30-34', 'M35-39', 'M40-44', 'M45-49', 'M50-54', \n",
    "           'M55-59', 'M60-64', 'M65-69', 'M70-74', 'M75-79', 'M80+', 'M80-84']\n",
    "pro_divs = ['MPRO', 'FPRO']\n",
    "keepvars = ['athleteid', 'gender', 'division', 'raceyear', 'venuename', 'swimtime', 'biketime', 'finish']\n",
    "\n",
    "\n",
    "# amateurs\n",
    "dfam = df.loc[(df.division.isin(ag_divs)) & (df.noswim == 0), keepvars]\n",
    "dfam.rename(columns={'venuename': 'venue'}, inplace=True)\n",
    "dfam = dfam.merge(dftemps, on='venue', how='right')\n",
    "dfam = dfam.loc[~dfam.venue.isin(['tulsa', 'kalmar'])]\n",
    "# print(dfam.venue.value_counts())\n",
    "\n",
    "# pros\n",
    "dfpro = df.loc[(df.division.isin(pro_divs)) & (df.noswim == 0), keepvars]\n",
    "dfpro.rename(columns={'venuename': 'venue'}, inplace=True)\n",
    "dfpro = dfpro.merge(dftemps, on='venue', how='right')\n",
    "dfpro = dfpro.loc[~dfpro.venue.isin(['kalmar', 'santa rosa', 'tulsa', 'maryland'])]\n",
    "# dfpro.venue.value_counts()\n",
    "\n",
    "\n",
    "# aggregate and plot means by avg water temp\n",
    "\n",
    "def agg_df(d, groupbyvars, aggf):\n",
    "    '''\n",
    "    Takes dflong and aggregates by groupbyvars the functions in aggf\n",
    "    '''\n",
    "    d = d.copy(deep=True)\n",
    "    d = d.loc[(d.finish != 'DQ') & ~((d.finish == 'FIN') & (d.swimtime.isnull())), :]\n",
    "    \n",
    "    # calc if DNF'd on swim\n",
    "    d['fin_swim'] = np.array(d.swimtime.notnull(), dtype=int)\n",
    "    \n",
    "    # calc finish rate by venue and avg swim time\n",
    "    dagg = d.loc[:, groupbyvars + ['swimtime', 'biketime', 'fin_swim', 'avg_water_temp']].groupby(groupbyvars).agg(aggf).reset_index()\n",
    "    \n",
    "    return dagg\n",
    "\n",
    "dfam = agg_df(dfam, ['venue'], 'mean')\n",
    "dfpro = agg_df(dfpro, ['venue'], 'mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter temp vs time\n",
    "\n",
    "plt.scatter(dfam.avg_water_temp, dfam.swimtime)\n",
    "plt.title('Amateur')\n",
    "plt.axvline(x=24.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(dfpro.avg_water_temp, dfpro.swimtime)\n",
    "plt.title('Pro')\n",
    "plt.axvline(x=21.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = [x for x in dfpro.venue] + [x for x in dfam.venue]\n",
    "print([x for x in dfpro.venue if x not in dfam.venue.unique()])\n",
    "print([x for x in dfam.venue if x not in dfpro.venue.unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea - use ag swim times to first-difference pro swim times, then look at differences around cutoff\n",
    "dfprom = dfam.iloc[:, :-1].copy()\n",
    "dfprom.columns = ['venue', 'swimtime_am', 'biketime_am', 'fin_swim_am']\n",
    "dfprom = dfpro.merge(dfprom, on='venue', how='left')\n",
    "dfprom['swim_diff'] = dfprom.swimtime - dfprom.swimtime_am\n",
    "\n",
    "plt.scatter(dfprom.avg_water_temp, dfprom.swim_diff)\n",
    "plt.title('Pro minus Amateur')\n",
    "plt.axvline(x=21.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dfprom.swimtime, dfprom.swimtime_am)\n",
    "m, b = np.polyfit(dfprom.swimtime, dfprom.swimtime_am, 1)\n",
    "x = range(2800, 3600)\n",
    "plt.plot(x, m*x + b, 'red')\n",
    "plt.xlabel('Pro swim time')\n",
    "plt.ylabel('Amateur swim time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load race-specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df with slots per ag per race\n",
    "dfs = pd.read_csv('../data/dfslot_full_wide.csv')\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge race-specific vars, like # finishers, % finishers\n",
    "\n",
    "dfrace = df.copy()\n",
    "\n",
    "# get dnf rates by sport - only count one sport for DNF\n",
    "dfrace['swimdnf'] = np.array((dfrace.swimtime.isnull()) & (dfrace.finish == \"DNF\"), dtype='int')\n",
    "dfrace['bikednf'] = np.array((dfrace.biketime.isnull()) & (dfrace.finish == \"DNF\") & \\\n",
    "                             (dfrace.swimdnf == 0), dtype='int')\n",
    "dfrace['rundnf'] = np.array((dfrace.runtime.isnull()) & (dfrace.finish == \"DNF\") & \\\n",
    "                            (dfrace.bikednf + dfrace.swimdnf == 0), dtype='int')\n",
    "dfrace['dnf'] = np.array((dfrace.finish == \"DNF\"), dtype='int')\n",
    "dfrace['dq'] = np.array((dfrace.finish == \"DQ\"), dtype='int')\n",
    "\n",
    "# get participant and finisher counts\n",
    "dfrace['participants'] = np.array(dfrace.finish.notnull(), dtype='int')\n",
    "dfrace['finishers'] = np.array(dfrace.finish == \"FIN\", dtype='int')\n",
    "dfrace.participants = dfrace.groupby('racename')['participants'].transform('sum')\n",
    "dfrace.finishers = dfrace.groupby('racename')['finishers'].transform('sum')\n",
    "\n",
    "# gender split\n",
    "dfrace['female'] = np.array(dfrace.gender == 'Female', dtype='int')\n",
    "\n",
    "# aggregate to race-level\n",
    "dfrace = dfrace.groupby(['racename', 'venuename', 'seriesid', 'raceyear', \\\n",
    "                         'racedate', 'konayear'],  as_index=False, observed=False)\\\n",
    "                    [['noswim', 'short', 'swimdnf', 'bikednf', \\\n",
    "                      'rundnf', 'dnf', 'dq', 'participants', \\\n",
    "                      'finishers', 'female']].aggregate(np.mean)\n",
    "\n",
    "# integer vars\n",
    "for i in ['noswim', 'short', 'participants', 'finishers']:\n",
    "    dfrace[i] = np.array(dfrace[i], dtype='int')\n",
    "\n",
    "dfrace.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix this inconsistency\n",
    "df.loc[df.seriesid == 54].racename.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up RD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cutoff times to dfs\n",
    "divlist = ['F18-24', 'F25-29', 'F30-34', 'F35-39', 'F40-44', 'F45-49', 'F50-54', \n",
    "           'F55-59', 'F60-64', 'F65-69', 'F70-74', 'F75-79', 'F80+', 'FPC', 'FPRO', \n",
    "           'M18-24', 'M25-29', 'M30-34', 'M35-39', 'M40-44', 'M45-49', 'M50-54', \n",
    "           'M55-59', 'M60-64', 'M65-69', 'M70-74', 'M75-79', 'M80+', 'M80-84', 'MPC', 'MPRO']\n",
    "racelist = df.racename.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export html\n",
    "\n",
    "Before committing:\n",
    "1. Save nb as html\n",
    "2. Clear nb of output (cell -> All output -> clear)\n",
    "3. Save nb\n",
    "4. Commit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --output-dir='../jupyter_html/' --to html analyze_imdata.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
